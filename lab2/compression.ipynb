{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a7d331",
   "metadata": {},
   "source": [
    "# Kompresja tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800a575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "from queue import LifoQueue\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ffd8e7",
   "metadata": {},
   "source": [
    "### Statyczny algorytm Huffmana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95585f25",
   "metadata": {},
   "source": [
    "Klasa reprezentująca węzeł w drzewie Huffmana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb11e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,weight, left=None, right=None, char=None):\n",
    "        self.weight=weight\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.char=char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a764cf",
   "metadata": {},
   "source": [
    "Funkcja zliczająca litery w tekście. Zwraca słownik {litera: ilość wystąpień}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fcbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_letters(text):\n",
    "    letter_counts=dict()\n",
    "    for letter in text:\n",
    "        if not letter in letter_counts:\n",
    "            letter_counts[letter]=0\n",
    "        else:\n",
    "            letter_counts[letter]+=1\n",
    "    return letter_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01528273",
   "metadata": {},
   "source": [
    "Funkcja budująca drzewo Huffmana na podstawie słownika zawierającego zliczone litery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe427de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_huffman_tree(letter_counts):\n",
    "    nodes=PriorityQueue()\n",
    "    for a, weight in letter_counts.items():\n",
    "        nodes.put((weight, a, Node(weight, char=a)))\n",
    "    while(nodes.qsize()>1):\n",
    "        element_1=nodes.get()\n",
    "        element_1, a= element_1[2],element_1[1]\n",
    "        element_2=nodes.get()[2]\n",
    "        nodes.put((element_1.weight+element_2.weight, a,Node(element_1.weight+element_2.weight, left=element_1, right=element_2)))\n",
    "    return nodes.get()[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbaf879",
   "metadata": {},
   "source": [
    "Funkcja zwracająca słownik {litera: kod Huffmana} na podstawie drzewa Huffmana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624c77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_huffman_code(huffman_tree):\n",
    "    stack=LifoQueue()\n",
    "    codes=dict()\n",
    "    stack.put((\"\", huffman_tree))\n",
    "    while(not stack.empty()):\n",
    "        code, node=stack.get()\n",
    "        if node.char is not None:\n",
    "            codes[node.char]=code\n",
    "        else:\n",
    "            if node.left is not None:\n",
    "                stack.put((code+\"0\", node.left))\n",
    "            if node.right is not None:\n",
    "                stack.put((code+\"1\", node.right))\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04f5d0",
   "metadata": {},
   "source": [
    "Funkcja (rekurencyjna) zwracająca drzewo Huffmana zapisane jako ciąg zer i jedynek.\\\n",
    "\\\n",
    "Sposób kodowania drzewa:\n",
    "* Stosujemy post-order traversal w przechodzeniu po drzewie.\n",
    "* Jeśli jesteśmy w węźle niebędącym liściem: kod lewego poddrzewa + kod prawego poddrzewa + '0'\n",
    "* Jeżeli jesteśmy w liściu: '1' + 8 bitowy kod znaku znajdującego się w liściu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64607b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_binary(node):\n",
    "    if node is None: return \"\"\n",
    "    elif node.char is not None:\n",
    "        char_bin=str(bin(node.char))[2:]\n",
    "        #char_bin=str(bin(ord(node.char)))[2:]\n",
    "        return \"1\"+\"0\"*(8-len(char_bin))+char_bin\n",
    "    else:\n",
    "        return tree_to_binary(node.left)+tree_to_binary(node.right)+\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40cc4b",
   "metadata": {},
   "source": [
    "Funkcja kompresująca plik i tworząca plik binarny o nazwie output_filename.\\\n",
    "\\\n",
    "Plik skompresowany ma postać:\n",
    "* Zakodowane drzewo Huffmana (niezbędne do dekompresji)\n",
    "* Jedno dodatkowe '0' sygnalizujące koniec bitów kodujących drzewo\n",
    "* Zakodowana zawartość pliku\\\n",
    "\\\n",
    "Na koniec zawartości pliku dodany został znak '$', który sygnalizuje koniec pliku. Dzięki temu przy dekompresji nie uzyskamy nadmiarowych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_huffman_encoding(text):\n",
    "    # $ będzie oznaczać koniec pliku, aby przy dekompresji nie uzyskac nadmiarowych danych\n",
    "    text.append(ord('$'))\n",
    "    h_tree=static_huffman_tree(count_letters(text))\n",
    "    h_code=static_huffman_code(h_tree)\n",
    "    encoded=tree_to_binary(h_tree)+\"0\"\n",
    "    for letter in text:\n",
    "        encoded=encoded+h_code[letter]\n",
    "    \n",
    "    buff=0\n",
    "    counter=0\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc48e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_huffman_encoding_files(input_file, output_filename):\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        text = bytearray(f.read())\n",
    "    start=time()\n",
    "    encoded=static_huffman_encoding(text)\n",
    "    end=time()\n",
    "    buff=0\n",
    "    counter=0\n",
    "    with open(output_filename+\".bin\", \"wb\") as f:\n",
    "        for bit in encoded:\n",
    "            buff=(buff << 1) | int(bit)\n",
    "            counter+=1\n",
    "            if counter == 8:\n",
    "                f.write(bytes([buff]))\n",
    "                buff=0\n",
    "                counter=0\n",
    "        if counter>0:\n",
    "            buff= buff << (8-counter)\n",
    "            f.write(bytes([buff])) \n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b80be",
   "metadata": {},
   "source": [
    "Funkcja dekompresująca plik z pliku binarnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a93af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_huffman_decoding(bin_str):\n",
    "    #rekonstrukcja drzewa\n",
    "    h_tree=None\n",
    "    q=LifoQueue()\n",
    "    i=0\n",
    "    while(True):\n",
    "        if bin_str[i]==\"1\":\n",
    "            char=bin_str[i+1:i+9]\n",
    "            q.put(Node(0,char=int(char, 2)))\n",
    "            #q.put(Node(0,char=chr(int(char, 2))))\n",
    "            i+=9\n",
    "        else:\n",
    "            i+=1\n",
    "            right=q.get()\n",
    "            if(q.empty()): \n",
    "                h_tree=right\n",
    "                break\n",
    "            left=q.get()\n",
    "            q.put(Node(0, left=left, right=right))   \n",
    "    #dekodowanie pliku\n",
    "    decoded=bytearray()\n",
    "    curr_node=h_tree\n",
    "    while i<len(bin_str):\n",
    "        if bin_str[i]=='0':\n",
    "            curr_node=curr_node.left\n",
    "        elif bin_str[i]=='1':\n",
    "            curr_node=curr_node.right\n",
    "        if curr_node.char is not None:\n",
    "            if curr_node.char==ord('$'): break\n",
    "            decoded.append(curr_node.char)\n",
    "            curr_node=h_tree\n",
    "        i+=1\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08d5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_huffman_decoding_files(input_file, output_file):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        buff = bytearray(f.read())\n",
    "\n",
    "    bin_str=''.join(f'{byte:08b}' for byte in buff)\n",
    "    \n",
    "    start=time()\n",
    "    decoded=static_huffman_decoding(bin_str)\n",
    "    end=time()\n",
    "\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        text = f.write(decoded)\n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c3c63",
   "metadata": {},
   "source": [
    "### Pliki testujące"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e4ef8",
   "metadata": {},
   "source": [
    "Wybrano: Iliadę Homera (w formacie txt) z projektu Gutenberg, plik inode.c z kodem źródłowym jądra Linuxa oraz wylosowano (poniżej) plik ze znakami losowanymi z rozkładu jednostajnego - uwzględniono 255 wartości poza wartością '$', gdyż znak ten na samym początku przyjęto za oznaczenie końca pliku.\n",
    "\n",
    "Iliadę i inode.c przycięto do rozmiarów 1kB, 10kB, 100kB, 1MB wykorzystując funkcje systemowe lub powielono treść tak by rozmiary były dokładne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c15a9",
   "metadata": {},
   "source": [
    "#### Generowanie plików z losowymi znakami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b459b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_file(filename, filesize): #filesize w bajtach\n",
    "    letters=np.random.randint(1,256,filesize)\n",
    "    #usuniecie $\n",
    "    mask= letters == ord('$')\n",
    "    letters[mask]=0\n",
    "    with open(filename, 'wb') as f:\n",
    "        for letter in letters:\n",
    "            f.write(bytes([letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e453991",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_random_file('text_files/random1kB.txt', 1024)\n",
    "generate_random_file('text_files/random10kB.txt', 10240)\n",
    "generate_random_file('text_files/random100kB.txt', 102400)\n",
    "generate_random_file('text_files/random1MB.txt', 1048576)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a60cc",
   "metadata": {},
   "source": [
    "### Kompresja i dekompresja z pomiarem czasu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027129d",
   "metadata": {},
   "source": [
    "#### Kompresja plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d4c288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_time_r1kB=static_huffman_encoding_files('text_files/random1kB.txt', 'compressed/random1kB')\n",
    "en_time_r10kB=static_huffman_encoding_files('text_files/random10kB.txt', 'compressed/random10kB')\n",
    "en_time_r100kB=static_huffman_encoding_files('text_files/random100kB.txt', 'compressed/random100kB')\n",
    "en_time_r1MB=static_huffman_encoding_files('text_files/random1MB.txt', 'compressed/random1MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5baa5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_time_il1kB=static_huffman_encoding_files('text_files/iliada1kB.txt', 'compressed/iliada1kB')\n",
    "en_time_il10kB=static_huffman_encoding_files('text_files/iliada10kB.txt', 'compressed/iliada10kB')\n",
    "en_time_il100kB=static_huffman_encoding_files('text_files/iliada100kB.txt', 'compressed/iliada100kB')\n",
    "en_time_il1MB=static_huffman_encoding_files('text_files/iliada1MB.txt', 'compressed/iliada1MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27e5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_time_in1kB=static_huffman_encoding_files('text_files/inode1kB.c', 'compressed/inode1kB')\n",
    "en_time_in10kB=static_huffman_encoding_files('text_files/inode10kB.c', 'compressed/inode10kB')\n",
    "en_time_in100kB=static_huffman_encoding_files('text_files/inode100kB.c', 'compressed/inode100kB')\n",
    "en_time_in1MB=static_huffman_encoding_files('text_files/inode1MB.c', 'compressed/inode1MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8f1f8",
   "metadata": {},
   "source": [
    "#### Dekompresja plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54ad7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_time_r1kB=static_huffman_decoding_files('compressed/random1kB.bin', 'decompressed/d_random1kB.txt')\n",
    "de_time_r10kB=static_huffman_decoding_files('compressed/random10kB.bin', 'decompressed/d_random10kB.txt')\n",
    "de_time_r100kB=static_huffman_decoding_files('compressed/random100kB.bin', 'decompressed/d_random100kB.txt')\n",
    "de_time_r1MB=static_huffman_decoding_files('compressed/random1MB.bin', 'decompressed/d_random1MB.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7925710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_time_il1kB=static_huffman_decoding_files('compressed/iliada1kB.bin', 'decompressed/d_iliada1kB.txt')\n",
    "de_time_il10kB=static_huffman_decoding_files('compressed/iliada10kB.bin', 'decompressed/d_iliada10kB.txt')\n",
    "de_time_il100kB=static_huffman_decoding_files('compressed/iliada100kB.bin', 'decompressed/d_iliada100kB.txt')\n",
    "de_time_il1MB=static_huffman_decoding_files('compressed/iliada1MB.bin', 'decompressed/d_iliada1MB.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6238a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_time_in1kB=static_huffman_decoding_files('compressed/inode1kB.bin', 'decompressed/d_inode1kB.c')\n",
    "de_time_in10kB=static_huffman_decoding_files('compressed/inode10kB.bin', 'decompressed/d_inode10kB.c')\n",
    "de_time_in100kB=static_huffman_decoding_files('compressed/inode100kB.bin', 'decompressed/d_inode100kB.c')\n",
    "de_time_in1MB=static_huffman_decoding_files('compressed/inode1MB.bin', 'decompressed/d_inode1MB.c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba12c7e",
   "metadata": {},
   "source": [
    "### Czasy kompresji i dekompresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bfbe80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1f6eb\">\n",
       "  <caption>Czasy kompresji</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1f6eb_level0_col0\" class=\"col_heading level0 col0\" >file</th>\n",
       "      <th id=\"T_1f6eb_level0_col1\" class=\"col_heading level0 col1\" >1kB</th>\n",
       "      <th id=\"T_1f6eb_level0_col2\" class=\"col_heading level0 col2\" >10kB</th>\n",
       "      <th id=\"T_1f6eb_level0_col3\" class=\"col_heading level0 col3\" >100kB</th>\n",
       "      <th id=\"T_1f6eb_level0_col4\" class=\"col_heading level0 col4\" >1MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1f6eb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1f6eb_row0_col0\" class=\"data row0 col0\" >inode.c</td>\n",
       "      <td id=\"T_1f6eb_row0_col1\" class=\"data row0 col1\" >0.002000</td>\n",
       "      <td id=\"T_1f6eb_row0_col2\" class=\"data row0 col2\" >0.004000</td>\n",
       "      <td id=\"T_1f6eb_row0_col3\" class=\"data row0 col3\" >0.027005</td>\n",
       "      <td id=\"T_1f6eb_row0_col4\" class=\"data row0 col4\" >0.945213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f6eb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1f6eb_row1_col0\" class=\"data row1 col0\" >iliada.txt</td>\n",
       "      <td id=\"T_1f6eb_row1_col1\" class=\"data row1 col1\" >0.000999</td>\n",
       "      <td id=\"T_1f6eb_row1_col2\" class=\"data row1 col2\" >0.004138</td>\n",
       "      <td id=\"T_1f6eb_row1_col3\" class=\"data row1 col3\" >0.028007</td>\n",
       "      <td id=\"T_1f6eb_row1_col4\" class=\"data row1 col4\" >0.841188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f6eb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1f6eb_row2_col0\" class=\"data row2 col0\" >random.txt</td>\n",
       "      <td id=\"T_1f6eb_row2_col1\" class=\"data row2 col1\" >0.003990</td>\n",
       "      <td id=\"T_1f6eb_row2_col2\" class=\"data row2 col2\" >0.007001</td>\n",
       "      <td id=\"T_1f6eb_row2_col3\" class=\"data row2 col3\" >0.029006</td>\n",
       "      <td id=\"T_1f6eb_row2_col4\" class=\"data row2 col4\" >1.987463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21f1e35e6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ixs=[\"inode.c\", \"iliada.txt\", \"random.txt\"]\n",
    "data_entimes={'file': ixs,\n",
    "      '1kB': [en_time_in1kB,en_time_il1kB,en_time_r1kB],\n",
    "      '10kB': [en_time_in10kB,en_time_il10kB,en_time_r10kB],\n",
    "      '100kB': [en_time_in100kB,en_time_il100kB,en_time_r100kB],\n",
    "      '1MB': [en_time_in1MB,en_time_il1MB,en_time_r1MB]}\n",
    "\n",
    "data_frame_entimes=pd.DataFrame(data_entimes)\n",
    "t_entimes=data_frame_entimes.style.set_caption(\"Czasy kompresji\")\n",
    "display(t_entimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f94faf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7719e\">\n",
       "  <caption>Czasy dekompresji</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7719e_level0_col0\" class=\"col_heading level0 col0\" >file</th>\n",
       "      <th id=\"T_7719e_level0_col1\" class=\"col_heading level0 col1\" >1kB</th>\n",
       "      <th id=\"T_7719e_level0_col2\" class=\"col_heading level0 col2\" >10kB</th>\n",
       "      <th id=\"T_7719e_level0_col3\" class=\"col_heading level0 col3\" >100kB</th>\n",
       "      <th id=\"T_7719e_level0_col4\" class=\"col_heading level0 col4\" >1MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7719e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7719e_row0_col0\" class=\"data row0 col0\" >inode.c</td>\n",
       "      <td id=\"T_7719e_row0_col1\" class=\"data row0 col1\" >0.001000</td>\n",
       "      <td id=\"T_7719e_row0_col2\" class=\"data row0 col2\" >0.014003</td>\n",
       "      <td id=\"T_7719e_row0_col3\" class=\"data row0 col3\" >0.129030</td>\n",
       "      <td id=\"T_7719e_row0_col4\" class=\"data row0 col4\" >1.305627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7719e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7719e_row1_col0\" class=\"data row1 col0\" >iliada.txt</td>\n",
       "      <td id=\"T_7719e_row1_col1\" class=\"data row1 col1\" >0.001999</td>\n",
       "      <td id=\"T_7719e_row1_col2\" class=\"data row1 col2\" >0.014004</td>\n",
       "      <td id=\"T_7719e_row1_col3\" class=\"data row1 col3\" >0.120027</td>\n",
       "      <td id=\"T_7719e_row1_col4\" class=\"data row1 col4\" >1.213304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7719e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7719e_row2_col0\" class=\"data row2 col0\" >random.txt</td>\n",
       "      <td id=\"T_7719e_row2_col1\" class=\"data row2 col1\" >0.004000</td>\n",
       "      <td id=\"T_7719e_row2_col2\" class=\"data row2 col2\" >0.022005</td>\n",
       "      <td id=\"T_7719e_row2_col3\" class=\"data row2 col3\" >0.190042</td>\n",
       "      <td id=\"T_7719e_row2_col4\" class=\"data row2 col4\" >1.910953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21f1f1b5c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_detimes={'file': ixs,\n",
    "      '1kB': [de_time_in1kB,de_time_il1kB,de_time_r1kB],\n",
    "      '10kB': [de_time_in10kB,de_time_il10kB,de_time_r10kB],\n",
    "      '100kB': [de_time_in100kB,de_time_il100kB,de_time_r100kB],\n",
    "      '1MB': [de_time_in1MB,de_time_il1MB,de_time_r1MB]}\n",
    "\n",
    "data_frame_detimes=pd.DataFrame(data_detimes)\n",
    "t_detimes=data_frame_detimes.style.set_caption(\"Czasy dekompresji\")\n",
    "display(t_detimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eeade5",
   "metadata": {},
   "source": [
    "### Współczynniki kompresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df91b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_rate(raw_name, compressed_name):\n",
    "    raw_stat=os.stat(raw_name)\n",
    "    comp_stat=os.stat(compressed_name)\n",
    "    return 1-comp_stat.st_size/raw_stat.st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da0b3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_318af\">\n",
       "  <caption>Współczynniki kompresji w procentach</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_318af_level0_col0\" class=\"col_heading level0 col0\" >file</th>\n",
       "      <th id=\"T_318af_level0_col1\" class=\"col_heading level0 col1\" >1kB</th>\n",
       "      <th id=\"T_318af_level0_col2\" class=\"col_heading level0 col2\" >10kB</th>\n",
       "      <th id=\"T_318af_level0_col3\" class=\"col_heading level0 col3\" >100kB</th>\n",
       "      <th id=\"T_318af_level0_col4\" class=\"col_heading level0 col4\" >1MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_318af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_318af_row0_col0\" class=\"data row0 col0\" >inode.c</td>\n",
       "      <td id=\"T_318af_row0_col1\" class=\"data row0 col1\" >0.329102</td>\n",
       "      <td id=\"T_318af_row0_col2\" class=\"data row0 col2\" >0.341406</td>\n",
       "      <td id=\"T_318af_row0_col3\" class=\"data row0 col3\" >0.356455</td>\n",
       "      <td id=\"T_318af_row0_col4\" class=\"data row0 col4\" >0.355742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_318af_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_318af_row1_col0\" class=\"data row1 col0\" >iliada.txt</td>\n",
       "      <td id=\"T_318af_row1_col1\" class=\"data row1 col1\" >0.272461</td>\n",
       "      <td id=\"T_318af_row1_col2\" class=\"data row1 col2\" >0.351465</td>\n",
       "      <td id=\"T_318af_row1_col3\" class=\"data row1 col3\" >0.421289</td>\n",
       "      <td id=\"T_318af_row1_col4\" class=\"data row1 col4\" >0.406939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_318af_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_318af_row2_col0\" class=\"data row2 col0\" >random.txt</td>\n",
       "      <td id=\"T_318af_row2_col1\" class=\"data row2 col1\" >-0.306641</td>\n",
       "      <td id=\"T_318af_row2_col2\" class=\"data row2 col2\" >-0.030957</td>\n",
       "      <td id=\"T_318af_row2_col3\" class=\"data row2 col3\" >-0.003008</td>\n",
       "      <td id=\"T_318af_row2_col4\" class=\"data row2 col4\" >-0.000262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21f1f1f7550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kB1=[comp_rate('text_files/inode1kB.c', 'compressed/inode1kB.bin'),\n",
    "    comp_rate('text_files/iliada1kB.txt', 'compressed/iliada1kB.bin'),\n",
    "    comp_rate('text_files/random1kB.txt', 'compressed/random1kB.bin')]\n",
    "\n",
    "kB10=[comp_rate('text_files/inode10kB.c', 'compressed/inode10kB.bin'),\n",
    "    comp_rate('text_files/iliada10kB.txt', 'compressed/iliada10kB.bin'),\n",
    "    comp_rate('text_files/random10kB.txt', 'compressed/random10kB.bin')]\n",
    "\n",
    "kB100=[comp_rate('text_files/inode100kB.c', 'compressed/inode100kB.bin'),\n",
    "    comp_rate('text_files/iliada100kB.txt', 'compressed/iliada100kB.bin'),\n",
    "    comp_rate('text_files/random100kB.txt', 'compressed/random100kB.bin')]\n",
    "\n",
    "MB1=[comp_rate('text_files/inode1MB.c', 'compressed/inode1MB.bin'),\n",
    "    comp_rate('text_files/iliada1MB.txt', 'compressed/iliada1MB.bin'),\n",
    "    comp_rate('text_files/random1MB.txt', 'compressed/random1MB.bin')]\n",
    "\n",
    "data={'file': ixs,\n",
    "      '1kB': kB1,\n",
    "      '10kB': kB10,\n",
    "      '100kB': kB100,\n",
    "      '1MB': MB1}\n",
    "\n",
    "data_frame=pd.DataFrame(data)\n",
    "t=data_frame.style.set_caption(\"Współczynniki kompresji w procentach\")\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f8eb8",
   "metadata": {},
   "source": [
    "Dzień dobry, \n",
    "\\\n",
    "oto moja realizacja zadania o kompresji tekstu.\\\n",
    "Niestety nie udało mi się znaleźć materiałów (w zeszłorocznym wykładzie ani w Internecie), które pomogłyby mi zrozumieć algorytm dynamicznego kodowania Huffmana na tyle by go zaimplementować. Na dodatek bardzo dużo czasu poświęciłam na walkę z Pythonem aby w odpowiedni sposób wczytywał i zapisywał pliki (szczególnie z uwzględnieniem znaków niedrukowalnych).\n",
    "\\\n",
    "Na posypanie solą ran powyższe współczynniki kompresji wyszły ujemne dla pliku z losowymi znakami! Myślę, że jest to spowodowane tym, że dodatkową pamięć w pliku skompresowanym zajmuje zapisanie drzewa dekompresji, które w przypadku tych plików jest zapewne całkiem sporych rozmiarów w porównaniu do reszty pliku. O poprawności mojego wnioskowania świadczy fakt, że współczynnik kompresji dla 1MB pliku random.txt jest większy (mimo że wciąż ujemny) niż dla plików mniejszych. \\\n",
    "\\\n",
    "Ola Smela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fdd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
